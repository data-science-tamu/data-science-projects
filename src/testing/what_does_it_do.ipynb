{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Matth\\AppData\\Local\\Temp\\ipykernel_24432\\2038284838.py:9: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf1 # Given code seems to use tensorflow v1\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# For easy testing (immediate evaluation)\n",
    "tf.compat.v1.enable_eager_execution() \n",
    "\n",
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 6 data files being trained from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**disp_coord**\n",
    "- Discrete coordinates [0, 256-0] - [256, 256-0]\n",
    "\n",
    "**disp_data**\n",
    "- A bunch of float pairs (what does it represent?). \n",
    "- *Is it the displacement at each of the discrete coordinates in disp_coord?*\n",
    "- *Based on it's usage in the provided code, seems to represent the axial displacement.*\n",
    "\n",
    "**m_data**\n",
    "- Young's Modulus? $256^2$ data points.\n",
    "- Is this representing the $E$?\n",
    "\n",
    "**nu_data**\n",
    "- Poisson's Ration, $\\nu$.\n",
    "- $256^2$ data points.\n",
    "\n",
    "**strain_coord**\n",
    "- $256^2$ data points\n",
    "- Discretized coordinates? [0.5, 255.5-0.5] - [255.5, 255.5-0.5]\n",
    "- Likely the discretized coordinates for **strain data**\n",
    "\n",
    "**strain_data**\n",
    "- $256^2$ data points\n",
    "- A bunch of float triplets. Could they represent:\n",
    "  - $\\epsilon_{xx}$\n",
    "  - $\\epsilon_{yy}$\n",
    "  - $\\gamma_{xy}$\n",
    "- Which would then mean it represents the displacements\n",
    "  - So would be used when positions are known, but both elasticity values (young's modulus and poisson's ratio) are unknown.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.58113883]\n",
      " [-1.26491106]\n",
      " [-0.9486833 ]\n",
      " [-0.63245553]\n",
      " [-0.31622777]\n",
      " [ 0.        ]\n",
      " [ 0.31622777]\n",
      " [ 0.63245553]\n",
      " [ 0.9486833 ]\n",
      " [ 1.26491106]\n",
      " [ 1.58113883]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "# Think back to z-scores and standardization in PHYS 216\n",
    "# The standard score of a sample x is calculated as:\n",
    "#     z = (x - u) / s\n",
    "# where u is the mean of the training samples or zero if with_mean=False, \n",
    "# and s is the standard deviation of the training samples\n",
    "ss_x = preprocessing.StandardScaler()\n",
    "\n",
    "x_disp = ss_x.fit_transform(np.asarray([i for i in range(11)]).reshape(-1, 1))\n",
    "print(x_disp) # Standardized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.12200177,  0.10389465,  0.06642234, -0.15831861],\n",
       "       [ 0.13928841,  0.12074088,  0.00070636,  0.02106507],\n",
       "       [-0.04056288,  0.12068689, -0.04376579, -0.04714163],\n",
       "       [-0.1917735 ,  0.14086233,  0.15685952,  0.06542458]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a random distribution based on a truncated normal with the \n",
    "# given standard deviation\n",
    "tf1.truncated_normal([4, 4], stddev = 0.1) # Only in v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1, 0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self evident. Creates a tensor of given shape initialized to the given\n",
    "# value (in this case 0.1)\n",
    "tf.constant(0.1, shape = [4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1],\n",
       "       [0.1, 0.1, 0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a variable version for tensor flow\n",
    "tf.Variable(tf.constant(0.1, shape = [3,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder (what is the point?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_1:0' shape=(None, 2) dtype=float32>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requires \n",
    "tf1.placeholder(tf.float32, [None, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n",
    "# x if x > 0\n",
    "# 0 otherwise\n",
    "# Returns a tensor\n",
    "tf.nn.relu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@akp83540/silu-sigmoid-linear-unit-activation-function-d9b6845f0c81 \n",
    "# SiLU or swish activation function\n",
    "# x * sigmoid(beta * x)\n",
    "# Returns a tensor\n",
    "tf.nn.swish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used in argument of activation function\n",
    "# good old matrix multiplication. Used to multiply previous h (hidden layer?)\n",
    "# with the current layers weights. (To which the current layers bias is added)\n",
    "# QUESTION: Pretty sure the use of tf.Variable makes these (h, W, b) modifiable \n",
    "# by the training portion of the code\n",
    "tf.matmul()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Calculation and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test tf math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The math part of the code uses the placeholders, I wonder if that is what enables\n",
    "it's use during the training portion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = tf1.constant(0.3, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d()\n",
    "tf.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.6666666, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Reduces the dimensions of a tensor by reducing the provided\n",
    "# dimension (default None, so all) to a single element equal to the mean\n",
    "# in that dimension.\n",
    "x = tf.constant([[2., 2.], [2., 2.], [0, 2]])\n",
    "print(tf.reduce_mean(x)) # Average of all the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf1.Session()\n",
    "session = tf.compat.v1.Session() # To read documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Where the Placeholders are used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From what I understand. This means that the placeholders (-s_----) are replaced\n",
    "by there none placeholder equivalents (the imported data, -_----)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The optional feed_dict argument allows the caller to override the value of \n",
    "# tensors in the graph. Each key in feed_dict can be one of the following types:\n",
    "#\n",
    "# - If the key is a tf.Tensor, the value may be a Python scalar, string, list, \n",
    "#   or numpy ndarray that can be converted to the same dtype as that tensor. \n",
    "#   Additionally, if the key is a tf.compat.v1.placeholder, the shape of the \n",
    "#   value will be checked for compatibility with the placeholder.\n",
    "# \n",
    "# - If the key is a tf.sparse.SparseTensor, the value should be a \n",
    "#   tf.compat.v1.SparseTensorValue.\n",
    "# \n",
    "# - If the key is a nested tuple of Tensors or SparseTensors, the value should \n",
    "#   be a nested tuple with the same structure that maps to their corresponding \n",
    "#   values as above.\n",
    "# \n",
    "# Each value in feed_dict must be convertible to a numpy array of the dtype of \n",
    "# the corresponding key.\n",
    "\n",
    "session.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
